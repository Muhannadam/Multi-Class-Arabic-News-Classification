import streamlit as st
import joblib
import re
import os
import requests
import nltk
from nltk.corpus import stopwords

# Load Groq API key from environment
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Load saved models and encoders
model = joblib.load('baseline_lr_model.pkl')
vectorizer = joblib.load('tfidf_vectorizer.pkl')
label_encoder = joblib.load('label_encoder.pkl')

# Load Arabic stopwords
try:
    stopwords.words('arabic')
except LookupError:
    nltk.download('stopwords')

arabic_stopwords = set(stopwords.words('arabic'))

# Arabic text preprocessing function
def clean_text(text):
    def remove_tashkeel(t): return re.sub(r'[\u0617-\u061A\u064B-\u0652]', '', t)
    def remove_repeated_chars(t): return re.sub(r'(.)\1{2,}', r'\1\1', t)

    text = remove_tashkeel(text)
    text = re.sub(r'[^\u0600-\u06FF\s]', ' ', text)
    text = re.sub(r'[\d\u0660-\u0669]+', ' ', text)
    text = remove_repeated_chars(text)
    text = re.sub(r'\s+', ' ', text).strip()
    tokens = [w for w in text.split() if w not in arabic_stopwords and len(w) > 1]
    return ' '.join(tokens)

# Groq summarization + title suggestion function
def summarize_and_suggest_title(text):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "allam-2-7b",
        "messages": [
            {"role": "system", "content": "ุฃูุช ูุณุงุนุฏ ุฐูู. ุนูุฏูุง ูุตูู ูุต ุทูููุ ูู ุจุงูุชุฑุงุญ ุนููุงููุง ูุตูุฑูุง ูุฌุฐุงุจูุง ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุซู ุจุชูุฎูุตู ุจุดูู ูุฎุชุตุฑ"},
            {"role": "user", "content": f"ูุฐุง ูู ูุต ุงูููุงู:\n\n{text}\n\nุฑุฌุงุกู: 1- ุงูุชุฑุญ ุนููุงููุง ุฐูููุง ููููุงู 2- ูุฎุต ุงูููุงู ูู ููุฑุฉ ูุตูุฑุฉ."}
        ],
        "temperature": 0.5,
        "max_tokens": 500
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"โ ุฎุทุฃ ูู ุงูุงุชุตุงู: {response.status_code} - {response.text}"
    except Exception as e:
        return f"โ ุฎุทุฃ ุฃุซูุงุก ุงูุชูุฎูุต: {str(e)}"

# Set page to RTL and Arabic font using HTML injection
st.markdown(
    """
    <style>
    body {
        direction: RTL;
        text-align: right;
        font-family: 'Arial', sans-serif;
    }
    .stTextArea textarea {
        direction: RTL;
        text-align: right;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Sidebar navigation
page = st.sidebar.selectbox("ุงูุชูู ุฅูู:", ["๐ ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ", "โน๏ธ ุญูู ุงููุดุฑูุน"])

# Main Page: Classification
if page == "๐ ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ":
    st.title("๐ ูุตูู ุงูุฃุฎุจุงุฑ ุงูุนุฑุจูุฉ")
    st.markdown("**ูุฐุง ุงููููุฐุฌ ูููู ุจุชุตููู ุงูููุงูุงุช ุงูุนุฑุจูุฉ ุฅูู ูุฆุงุช ุฅุฎุจุงุฑูุฉุ ูููุชุฑุญ ุนููุงููุง ุฐูููุง ูููุฏู ุชูุฎูุตูุง ููุฌุฒูุง ุจุงุณุชุฎุฏุงู ุชูููุฉ Groq AI.**")

    input_text = st.text_area("โ๏ธ ุฃุฏุฎู ุงูููุงู ุฃู ุงููุต ุงูุฅุฎุจุงุฑู ููุง:", height=200)

    if st.button("๐ ุชุตููู ุงูููุงู"):
        if input_text.strip() == "":
            st.warning("โ๏ธ ุงูุฑุฌุงุก ุฅุฏุฎุงู ูุต.")
        else:
            # Preprocess + predict
            cleaned = clean_text(input_text)
            tfidf_input = vectorizer.transform([cleaned])
            pred = model.predict(tfidf_input)
            label = label_encoder.inverse_transform(pred)[0]
            st.success(f"โ ุงููุฆุฉ ุงููุชููุนุฉ: **{label}**")

            # Summarization + title suggestion
            with st.spinner("โ๏ธ ุฌุงุฑู ุงูุชูุฎูุต ูุงูุชุฑุงุญ ุงูุนููุงู..."):
                summary_output = summarize_and_suggest_title(input_text)
                st.subheader("๐ ุงูุชูุฎูุต ูุงูุนููุงู ุงูููุชุฑุญ:")
                st.markdown(summary_output)

# About Page
elif page == "โน๏ธ ุญูู ุงููุดุฑูุน":
    st.title("โน๏ธ ูุนูููุงุช ุนู ุงููุดุฑูุน")
    st.markdown("""
    ูุฐุง ุงููุดุฑูุน ูู ูุธุงู ุชุตููู ุฐูู ููููุงูุงุช ุงูุฅุฎุจุงุฑูุฉ ุงูุนุฑุจูุฉุ ูุนุชูุฏ ุนูู ูููุฐุฌ **Logistic Regression** ูุฏุฑุจ ุจุงุณุชุฎุฏุงู ุจูุงูุงุช **SANAD Dataset**.
    
    ุงููุฒุงูุง:
    - ุชุตููู ุงูููุงูุงุช ุฅูู ูุฆุงุช ูุซู ุงูุณูุงุณุฉุ ุงูุฑูุงุถุฉุ ุงูุตุญุฉุ ุงูุฏููุ ูุบูุฑูุง.
    - ุชูุฎูุต ุงูููุงู ุชููุงุฆููุง ูุงูุชุฑุงุญ ุนููุงู ุฐูู ุจุงุณุชุฎุฏุงู ูููุฐุฌ **Allam-2-7B** ูู ููุตุฉ **Groq**.
    - ูุงุฌูุฉ ุชูุงุนููุฉ ูุจููุฉ ุจุงุณุชุฎุฏุงู **Streamlit**.

    ุงูุชูููุฉ ุงููุณุชุฎุฏูุฉ:
    - Python (scikit-learn, joblib, NLTK)
    - Groq API (Allam-2-7B)
    - Streamlit
    - GitHub + Streamlit Cloud

    ๐ ูุฐุง ุงููุดุฑูุน ููุฏู ุฅูู ุชุนุฒูุฒ ูุนุงูุฌุฉ ุงููุบุฉ ุงูุนุฑุจูุฉ ุจุงุณุชุฎุฏุงู ุชูููุงุช ุญุฏูุซุฉ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู.
    """)
